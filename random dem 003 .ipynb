{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d4fb1-c7a1-43d1-a585-a976fa499a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn imbalanced-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84a769-8600-4453-bb2b-c0e6029986f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Suppress potential warnings from scikit-learn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Define File Path and Columns ---\n",
    "\n",
    "# The new file path to your social data subset.\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social data Part 2 new .csv\"\n",
    "\n",
    "# The columns relevant to this dataset, as requested.\n",
    "# The `Mental Illness` column is our target.\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# We need to make sure the data contains only the columns we need for this analysis\n",
    "# and handle any missing values in the target variable.\n",
    "data = data[columns_to_use]\n",
    "target_column = 'Mental Illness'\n",
    "data.dropna(subset=[target_column], inplace=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Convert categorical features to dummy/indicator variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# --- 3. Check for Multicollinearity ---\n",
    "\n",
    "print(\"\\nChecking for multicollinearity...\")\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = X_encoded.corr()\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', mask=mask)\n",
    "plt.title('Correlation Matrix of Social Features')\n",
    "plt.savefig(\"social_correlation_matrix.png\")\n",
    "print(\"\\nCorrelation matrix heatmap plot saved as 'social_correlation_matrix.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Identify highly correlated features (e.g., correlation > 0.8)\n",
    "threshold = 0.8\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "if to_drop:\n",
    "    print(f\"\\nFeatures with multicollinearity (correlation > {threshold}):\")\n",
    "    print(to_drop)\n",
    "else:\n",
    "    print(f\"\\nNo features with multicollinearity found above the {threshold} threshold.\")\n",
    "\n",
    "# --- Drop Multicollinear Features ---\n",
    "if 'Household Composition_NOT APPLICABLE' in X_encoded.columns:\n",
    "    X_encoded = X_encoded.drop(columns=['Household Composition_NOT APPLICABLE'])\n",
    "    print(\"\\nRemoved multicollinear feature: Household Composition_NOT APPLICABLE\")\n",
    "\n",
    "# Split the data into a training set (70%) and a testing set (30%).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# --- 4. Address Class Imbalance with SMOTE ---\n",
    "\n",
    "print(\"\\nApplying SMOTE to the training data to balance the classes...\")\n",
    "# We will oversample the minority classes to a smaller, more manageable size\n",
    "target_counts = Counter(y_train)\n",
    "# Set the sampling strategy to oversample minority classes to a more balanced number\n",
    "sampling_strategy = {\n",
    "    'NO': int(target_counts['NO'] * 1.5),\n",
    "    'UNKNOWN': int(target_counts['UNKNOWN'] * 1.5),\n",
    "    'YES': target_counts['YES']\n",
    "}\n",
    "\n",
    "sm = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print(\"New class distribution in training data:\", Counter(y_train_res))\n",
    "\n",
    "# --- 5. Train the Random Forest Model on Balanced Data ---\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "print(\"\\nTraining the Random Forest model on the new, balanced data...\")\n",
    "model.fit(X_train_res, y_train_res)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- 6. Evaluate the Model ---\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy after SMOTE: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report after SMOTE:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the feature importances from the final model\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_encoded.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# --- 7. Plot and Save Feature Importances ---\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importances.head(10).sort_values().plot(kind='barh')\n",
    "plt.title('Top 10 Most Important Social Features for Predicting Mental Illness (with SMOTE)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "output_file = \"social_feature_importance_plot.png\"\n",
    "plt.savefig(output_file)\n",
    "print(f\"\\nPlot saved successfully as '{output_file}'\")\n",
    "plt.close()\n",
    "\n",
    "# --- 8. Generate new visualizations for key features ---\n",
    "print(\"\\nGenerating new visualizations for key features...\")\n",
    "\n",
    "# Create a figure with a subplot for each plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "fig.suptitle('Relationship Between Top Social Features and Mental Illness', fontsize=18)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot 1: Special Education Services vs. Mental Illness\n",
    "sns.countplot(data=data, x='Special Education Services', hue=target_column, ax=axes[0])\n",
    "axes[0].set_title('Mental Illness by Special Education Services')\n",
    "axes[0].set_xlabel('Special Education Services')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Plot 2: Household Composition vs. Mental Illness\n",
    "sns.countplot(data=data, x='Household Composition', hue=target_column, ax=axes[1])\n",
    "axes[1].set_title('Mental Illness by Household Composition')\n",
    "axes[1].set_xlabel('Household Composition')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Race vs. Mental Illness\n",
    "sns.countplot(data=data, x='Race', hue=target_column, ax=axes[2])\n",
    "axes[2].set_title('Mental Illness by Race')\n",
    "axes[2].set_xlabel('Race')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 4: Religious Preference vs. Mental Illness\n",
    "sns.countplot(data=data, x='Religious Preference', hue=target_column, ax=axes[3])\n",
    "axes[3].set_title('Mental Illness by Religious Preference')\n",
    "axes[3].set_xlabel('Religious Preference')\n",
    "axes[3].set_ylabel('Count')\n",
    "axes[3].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "output_file_visuals = \"social_feature_visualizations.png\"\n",
    "plt.savefig(output_file_visuals)\n",
    "print(f\"New visualizations for key social features saved as '{output_file_visuals}'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694427a-664f-44a7-ac9a-00ed47c2fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social data Part 2 new .csv\"\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# 2. Clean and Prepare\n",
    "data = data[columns_to_use]\n",
    "data.dropna(subset=['Mental Illness'], inplace=True)\n",
    "data = data[data['Mental Illness'].isin(['YES', 'NO'])]  # Remove 'UNKNOWN'\n",
    "\n",
    "X = data.drop(columns=['Mental Illness'])\n",
    "y = data['Mental Illness']\n",
    "\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "X_encoded = X_encoded.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# 3. Check for Multicollinearity\n",
    "corr_matrix = X_encoded.corr()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "\n",
    "if to_drop:\n",
    "    print(f\"\\nFeatures with multicollinearity (correlation > 0.8):\")\n",
    "    print(to_drop)\n",
    "    X_encoded.drop(columns=to_drop, inplace=True)\n",
    "    print(f\"\\nRemoved multicollinear features: {to_drop}\")\n",
    "else:\n",
    "    print(\"\\nNo features with multicollinearity found.\")\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# 5. Apply SMOTE\n",
    "print(\"\\nApplying SMOTE to the training data to balance the classes...\")\n",
    "X_train = X_train.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print(\"New class distribution in training data:\", Counter(y_train_res))\n",
    "\n",
    "# 6. Train Model\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "print(\"\\nModel training complete!\")\n",
    "\n",
    "# 7. Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy after SMOTE: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report after SMOTE:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. Feature Importances\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_encoded.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importances.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807ba2f-c0b8-46fe-ae47-b8f0ccb8a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Suppress potential warnings from scikit-learn and imbalanced-learn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Define File Path and Columns ---\n",
    "\n",
    "# The new file path to your social data subset.\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social data Part 2 new .csv\"\n",
    "\n",
    "# The columns relevant to this dataset, as requested.\n",
    "# The `Mental Illness` column is our target.\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# We need to make sure the data contains only the columns we need for this analysis\n",
    "# and handle any missing values in the target variable.\n",
    "data = data[columns_to_use]\n",
    "target_column = 'Mental Illness'\n",
    "data.dropna(subset=[target_column], inplace=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Convert categorical features to dummy/indicator variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# --- 3. Check for Multicollinearity ---\n",
    "\n",
    "print(\"\\nChecking for multicollinearity...\")\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = X_encoded.corr()\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', mask=mask)\n",
    "plt.title('Correlation Matrix of Social Features')\n",
    "plt.savefig(\"social_correlation_matrix.png\")\n",
    "print(\"\\nCorrelation matrix heatmap plot saved as 'social_correlation_matrix.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Identify highly correlated features (e.g., correlation > 0.8)\n",
    "threshold = 0.8\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "if to_drop:\n",
    "    print(f\"\\nFeatures with multicollinearity (correlation > {threshold}):\")\n",
    "    print(to_drop)\n",
    "else:\n",
    "    print(f\"\\nNo features with multicollinearity found above the {threshold} threshold.\")\n",
    "\n",
    "# --- Drop Multicollinear Features ---\n",
    "if 'Household Composition_NOT APPLICABLE' in X_encoded.columns:\n",
    "    X_encoded = X_encoded.drop(columns=['Household Composition_NOT APPLICABLE'])\n",
    "    print(\"\\nRemoved multicollinear feature: Household Composition_NOT APPLICABLE\")\n",
    "\n",
    "# Split the data into a training set (70%) and a testing set (30%).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# --- 4. Train the BalancedRandomForestClassifier ---\n",
    "\n",
    "# Using BalancedRandomForestClassifier instead of SMOTE\n",
    "model = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, sampling_strategy='not majority')\n",
    "print(\"\\nTraining the BalancedRandomForestClassifier on the data...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- 5. Evaluate the Model ---\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the feature importances from the final model\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_encoded.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# --- 6. Plot and Save Feature Importances ---\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importances.head(10).sort_values().plot(kind='barh')\n",
    "plt.title('Top 10 Most Important Social Features (BalancedRandomForestClassifier)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "output_file = \"social_feature_importance_plot_brf.png\"\n",
    "plt.savefig(output_file)\n",
    "print(f\"\\nPlot saved successfully as '{output_file}'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cae37-4a53-40ca-b693-a5f559404e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Suppress potential warnings from scikit-learn and imbalanced-learn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Define File Path and Columns ---\n",
    "\n",
    "# The new file path to your social data subset.\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social data Part 2 new .csv\"\n",
    "\n",
    "# The columns relevant to this dataset, as requested.\n",
    "# The `Mental Illness` column is our target.\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# We need to make sure the data contains only the columns we need for this analysis\n",
    "# and handle any missing values in the target variable.\n",
    "data = data[columns_to_use]\n",
    "target_column = 'Mental Illness'\n",
    "data.dropna(subset=[target_column], inplace=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Convert categorical features to dummy/indicator variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# --- 3. Check for Multicollinearity ---\n",
    "\n",
    "print(\"\\nChecking for multicollinearity...\")\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = X_encoded.corr()\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', mask=mask)\n",
    "plt.title('Correlation Matrix of Social Features')\n",
    "plt.savefig(\"social_correlation_matrix.png\")\n",
    "print(\"\\nCorrelation matrix heatmap plot saved as 'social_correlation_matrix.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Identify highly correlated features (e.g., correlation > 0.8)\n",
    "threshold = 0.8\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "if to_drop:\n",
    "    print(f\"\\nFeatures with multicollinearity (correlation > {threshold}):\")\n",
    "    print(to_drop)\n",
    "else:\n",
    "    print(f\"\\nNo features with multicollinearity found above the {threshold} threshold.\")\n",
    "\n",
    "# --- Drop Multicollinear Features ---\n",
    "if 'Household Composition_NOT APPLICABLE' in X_encoded.columns:\n",
    "    X_encoded = X_encoded.drop(columns=['Household Composition_NOT APPLICABLE'])\n",
    "    print(\"\\nRemoved multicollinear feature: Household Composition_NOT APPLICABLE\")\n",
    "\n",
    "# Split the data into a training set (70%) and a testing set (30%).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# --- 4. Train the BalancedRandomForestClassifier ---\n",
    "\n",
    "# Using BalancedRandomForestClassifier instead of SMOTE\n",
    "model = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, sampling_strategy='not majority')\n",
    "print(\"\\nTraining the BalancedRandomForestClassifier on the data...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- 5. Evaluate the Model ---\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the feature importances from the final model\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_encoded.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# --- 6. Plot and Save Feature Importances ---\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importances.head(10).sort_values().plot(kind='barh')\n",
    "plt.title('Top 10 Most Important Social Features (BalancedRandomForestClassifier)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "output_file = \"social_feature_importance_plot_brf.png\"\n",
    "plt.savefig(output_file)\n",
    "print(f\"\\nPlot saved successfully as '{output_file}'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396710b0-42a5-4981-bdba-9d4d6bbaad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f7570-fb75-4080-957b-797a4684c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "print(\"Exists:\", os.path.exists(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88220469-3b19-479e-82b5-95a217230774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load Data\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# 2. Clean and Prepare\n",
    "data = data[columns_to_use]\n",
    "data.dropna(subset=['Mental Illness'], inplace=True)\n",
    "data = data[data['Mental Illness'].isin(['YES', 'NO'])]\n",
    "\n",
    "X = data.drop(columns=['Mental Illness'])\n",
    "y = data['Mental Illness']\n",
    "\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "X_encoded = X_encoded.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# 3. Check for Multicollinearity\n",
    "corr_matrix = X_encoded.corr()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "if to_drop:\n",
    "    print(f\"\\nFeatures with multicollinearity (correlation > 0.8):\")\n",
    "    print(to_drop)\n",
    "    X_encoded.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# 5. Train BalancedRandomForestClassifier\n",
    "model = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"\\nModel training complete!\")\n",
    "\n",
    "# 6. Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 7. Feature Importances\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_encoded.columns).sort_values(ascending=False)\n",
    "top_features = feature_importances.head(10)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(top_features)\n",
    "\n",
    "# 8. Export Feature Importance Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features.sort_values().plot(kind='barh')\n",
    "plt.title('Top 10 Most Important Features (BalancedRandomForestClassifier)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"top_10_feature_importance.png\")\n",
    "plt.close()\n",
    "print(\"\\nFeature importance plot saved as 'top_10_feature_importance.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efcf489-1f7d-4f8e-b619-9b8aa12d868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the multicollinear feature\n",
    "df = df.drop(columns=['Household Composition'])\n",
    "\n",
    "# Define target and features\n",
    "target = 'Mental Illness'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTE + Tomek Links\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled_tomek, y_resampled_tomek = smote_tomek.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# Apply SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled_enn, y_resampled_enn = smote_enn.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# Train and evaluate BalancedRandomForestClassifier on SMOTE + Tomek Links\n",
    "model_tomek = BalancedRandomForestClassifier(random_state=42)\n",
    "model_tomek.fit(X_resampled_tomek, y_resampled_tomek)\n",
    "y_pred_tomek = model_tomek.predict(X_test_encoded)\n",
    "\n",
    "print(\"=== SMOTE + Tomek Links ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tomek))\n",
    "print(classification_report(y_test, y_pred_tomek))\n",
    "print(confusion_matrix(y_test, y_pred_tomek))\n",
    "\n",
    "# Train and evaluate BalancedRandomForestClassifier on SMOTEENN\n",
    "model_enn = BalancedRandomForestClassifier(random_state=42)\n",
    "model_enn.fit(X_resampled_enn, y_resampled_enn)\n",
    "y_pred_enn = model_enn.predict(X_test_encoded)\n",
    "\n",
    "print(\"\\n=== SMOTEENN ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_enn))\n",
    "print(classification_report(y_test, y_pred_enn))\n",
    "print(confusion_matrix(y_test, y_pred_enn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa9aee-7800-4d0a-97f5-3139d9c50e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show basic info\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f7370-4588-45c2-a16a-abf617738604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show basic info\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd839a34-bc82-45f2-a6f8-2b4002f91c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Step 2: Load dataset\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Drop irrelevant and multicollinear columns\n",
    "columns_to_drop = [\n",
    "    'Household Composition', 'Survey Year', 'Program Category',\n",
    "    'Region Served', 'Patient ID', 'Age Group', 'Sex'\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 4: Define features and target\n",
    "target = 'Mental Illness'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Step 5: Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Step 6: One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Step 7: Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 8: Preprocess data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Step 9: Apply SMOTE + Tomek Links\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled_tomek, y_resampled_tomek = smote_tomek.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# Step 10: Apply SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled_enn, y_resampled_enn = smote_enn.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# Step 11: Train and evaluate BalancedRandomForestClassifier on SMOTE + Tomek Links\n",
    "model_tomek = BalancedRandomForestClassifier(random_state=42)\n",
    "model_tomek.fit(X_resampled_tomek, y_resampled_tomek)\n",
    "y_pred_tomek = model_tomek.predict(X_test_encoded)\n",
    "\n",
    "print(\"=== SMOTE + Tomek Links ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tomek))\n",
    "print(classification_report(y_test, y_pred_tomek))\n",
    "print(confusion_matrix(y_test, y_pred_tomek))\n",
    "\n",
    "# Step 12: Train and evaluate BalancedRandomForestClassifier on SMOTEENN\n",
    "model_enn = BalancedRandomForestClassifier(random_state=42)\n",
    "model_enn.fit(X_resampled_enn, y_resampled_enn)\n",
    "y_pred_enn = model_enn.predict(X_test_encoded)\n",
    "\n",
    "print(\"\\n=== SMOTEENN ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_enn))\n",
    "print(classification_report(y_test, y_pred_enn))\n",
    "print(confusion_matrix(y_test, y_pred_enn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f994f-ed81-4878-9569-051c586a4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the data\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "# Drop multicollinear and irrelevant columns\n",
    "columns_to_drop = [\n",
    "    'Household Composition', 'Survey Year', 'Program Category',\n",
    "    'Region Served', 'Patient ID', 'Age Group', 'Sex'\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "# Define target and features\n",
    "target = 'Mental Illness'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y, test_size=0.3, random_state=42)\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# SMOTE + Tomek Links\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled_tomek, y_resampled_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled_enn, y_resampled_enn = smote_enn.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be51c7-722f-426e-be4c-a899316fe14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train on SMOTE + Tomek Links\n",
    "model_tomek = BalancedRandomForestClassifier(random_state=42)\n",
    "model_tomek.fit(X_resampled_tomek, y_resampled_tomek)\n",
    "y_pred_tomek = model_tomek.predict(X_test)\n",
    "\n",
    "print(\"=== SMOTE + Tomek Links ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tomek))\n",
    "print(classification_report(y_test, y_pred_tomek))\n",
    "print(confusion_matrix(y_test, y_pred_tomek))\n",
    "\n",
    "# Train on SMOTEENN\n",
    "model_enn = BalancedRandomForestClassifier(random_state=42)\n",
    "model_enn.fit(X_resampled_enn, y_resampled_enn)\n",
    "y_pred_enn = model_enn.predict(X_test)\n",
    "\n",
    "print(\"\\n=== SMOTEENN ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_enn))\n",
    "print(classification_report(y_test, y_pred_enn))\n",
    "print(confusion_matrix(y_test, y_pred_enn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2370cb-06c1-46ad-9015-75929f0d6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn scikit-learn pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f652d70-461b-45cb-a980-4212fab32274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train on SMOTE + Tomek Links\n",
    "model_tomek = BalancedRandomForestClassifier(random_state=42)\n",
    "model_tomek.fit(X_resampled_tomek, y_resampled_tomek)\n",
    "y_pred_tomek = model_tomek.predict(X_test)\n",
    "\n",
    "print(\"=== SMOTE + Tomek Links ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tomek))\n",
    "print(classification_report(y_test, y_pred_tomek))\n",
    "print(confusion_matrix(y_test, y_pred_tomek))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1440e-1d84-4bf3-8dc5-cd05006768e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Try resampling only SMOTE + Tomek Links\n",
    "try:\n",
    "    smote_tomek = SMOTETomek(random_state=42)\n",
    "    X_resampled_tomek, y_resampled_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "    print(\"SMOTE + Tomek Links resampling successful!\")\n",
    "    print(\"Resampled shape:\", X_resampled_tomek.shape, y_resampled_tomek.shape)\n",
    "except Exception as e:\n",
    "    print(\"Error during SMOTE + Tomek Links:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b3b9b-f8a5-40ec-bb4e-48da02c9ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the encoded data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006b71f-6393-4ad5-aa8f-eaf1ebb18c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "X_encoded = preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f2f13-9136-47bd-8afd-ed019bba7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target = 'Mental Illness'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a66827-b5c4-47d1-ae92-1b9c591c416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Household Composition', 'Survey Year', 'Program Category',\n",
    "    'Region Served', 'Patient ID', 'Age Group', 'Sex'\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e4cb1-ad14-40cb-a652-9e1ba3dce0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target = 'Mental Illness'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41c3ad-3ffa-4547-a902-87903d8585ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "X_encoded = preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ffd65-e2b1-4531-9f7b-21063d4e280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the encoded data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6333b-e1f7-44f6-b6d0-2c78e757995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# SMOTE + Tomek Links\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled_tomek, y_resampled_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled_enn, y_resampled_enn = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"SMOTE + Tomek Links shape:\", X_resampled_tomek.shape)\n",
    "print(\"SMOTEENN shape:\", X_resampled_enn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c097d-ad86-46f4-8317-d59da5be13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train on SMOTE + Tomek Links\n",
    "model_tomek = BalancedRandomForestClassifier(random_state=42)\n",
    "model_tomek.fit(X_resampled_tomek, y_resampled_tomek)\n",
    "y_pred_tomek = model_tomek.predict(X_test)\n",
    "\n",
    "print(\"=== SMOTE + Tomek Links ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tomek))\n",
    "print(classification_report(y_test, y_pred_tomek))\n",
    "print(confusion_matrix(y_test, y_pred_tomek))\n",
    "\n",
    "# Train on SMOTEENN\n",
    "model_enn = BalancedRandomForestClassifier(random_state=42)\n",
    "model_enn.fit(X_resampled_enn, y_resampled_enn)\n",
    "y_pred_enn = model_enn.predict(X_test)\n",
    "\n",
    "print(\"\\n=== SMOTEENN ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_enn))\n",
    "print(classification_report(y_test, y_pred_enn))\n",
    "print(confusion_matrix(y_test, y_pred_enn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb29a1e4-5b53-41b2-b831-2ef236bae1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Suppress potential warnings from scikit-learn and imbalanced-learn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Define File Path and Columns ---\n",
    "\n",
    "# The new file path to your social data subset.\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "\n",
    "# The columns relevant to this dataset, as requested.\n",
    "# The `Mental Illness` column is our target.\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# We need to make sure the data contains only the columns we need for this analysis\n",
    "# and handle any missing values in the target variable.\n",
    "data = data[columns_to_use]\n",
    "target_column = 'Mental Illness'\n",
    "data.dropna(subset=[target_column], inplace=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Convert categorical features to dummy/indicator variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# --- 3. Check for Multicollinearity ---\n",
    "\n",
    "print(\"\\nChecking for multicollinearity...\")\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = X_encoded.corr()\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', mask=mask)\n",
    "plt.title('Correlation Matrix of Social Features')\n",
    "plt.savefig(\"social_correlation_matrix.png\")\n",
    "print(\"\\nCorrelation matrix heatmap plot saved as 'social_correlation_matrix.png'\")\n",
    "plt.close()\n",
    "\n",
    "# Identify highly correlated features (e.g., correlation > 0.8)\n",
    "threshold = 0.8\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "if to_drop:\n",
    "    print(f\"\\nFeatures with multicollinearity (correlation > {threshold}):\")\n",
    "    print(to_drop)\n",
    "else:\n",
    "    print(f\"\\nNo features with multicollinearity found above the {threshold} threshold.\")\n",
    "\n",
    "# --- Drop Multicollinear Features ---\n",
    "if 'Household Composition_NOT APPLICABLE' in X_encoded.columns:\n",
    "    X_encoded = X_encoded.drop(columns=['Household Composition_NOT APPLICABLE'])\n",
    "    print(\"\\nRemoved multicollinear feature: Household Composition_NOT APPLICABLE\")\n",
    "\n",
    "# Split the data into a training set (70%) and a testing set (30%).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# --- 4. Train the BalancedRandomForestClassifier ---\n",
    "\n",
    "# Using BalancedRandomForestClassifier for handling class imbalance\n",
    "model = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, sampling_strategy='not majority')\n",
    "print(\"\\nTraining the BalancedRandomForestClassifier on the data...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- 5. Evaluate the Model ---\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the feature importances from the final model\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_encoded.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# --- 6. Plot and Save Feature Importances ---\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importances.head(10).sort_values().plot(kind='barh')\n",
    "plt.title('Top 10 Most Important Social Features (BalancedRandomForestClassifier)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "# The plot will be saved in your project's main folder\n",
    "output_file = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\social_feature_importance_plot_brf.png\"\n",
    "plt.savefig(output_file)\n",
    "print(f\"\\nPlot saved successfully as '{output_file}'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8ad0d-f1a2-4e69-9182-1342197ab4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "# Suppress potential warnings from scikit-learn and imbalanced-learn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Define File Path and Columns ---\n",
    "\n",
    "# The file path to your social data subset.\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "\n",
    "# The columns relevant to this dataset, as requested.\n",
    "# The `Mental Illness` column is our target.\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# We need to make sure the data contains only the columns we need for this analysis\n",
    "# and handle any missing values in the target variable.\n",
    "data = data[columns_to_use]\n",
    "target_column = 'Mental Illness'\n",
    "data.dropna(subset=[target_column], inplace=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Convert categorical features to dummy/indicator variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# --- Drop Multicollinear Features ---\n",
    "if 'Household Composition_NOT APPLICABLE' in X_encoded.columns:\n",
    "    X_encoded = X_encoded.drop(columns=['Household Composition_NOT APPLICABLE'])\n",
    "    print(\"\\nRemoved multicollinear feature: Household Composition_NOT APPLICABLE\")\n",
    "    print(f\"New feature set shape after removing multicollinearity: {X_encoded.shape}\")\n",
    "\n",
    "# --- 3. Feature Selection with RFE ---\n",
    "\n",
    "print(\"\\nPerforming Recursive Feature Elimination (RFE) to select top 10 features...\")\n",
    "# Use BalancedRandomForestClassifier as the estimator for RFE\n",
    "rfe_estimator = BalancedRandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, sampling_strategy='not majority')\n",
    "rfe = RFE(estimator=rfe_estimator, n_features_to_select=10, step=1)\n",
    "rfe.fit(X_encoded, y)\n",
    "\n",
    "# Get the list of top 10 selected features\n",
    "selected_features = X_encoded.columns[rfe.support_].tolist()\n",
    "print(f\"RFE selected the following features: {selected_features}\")\n",
    "\n",
    "# Filter the data to include only the selected features\n",
    "X_rfe = X_encoded[selected_features]\n",
    "\n",
    "# --- 4. Train-Test Split on RFE-selected data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# --- 5. Train the BalancedRandomForestClassifier on RFE-selected data ---\n",
    "model = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, sampling_strategy='not majority')\n",
    "print(\"\\nTraining the final BalancedRandomForestClassifier on RFE-selected data...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- 6. Evaluate the Model ---\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --- 7. Generate SHAP Summary Plot for Interpretability ---\n",
    "print(\"\\nGenerating SHAP summary plot for model interpretability...\")\n",
    "\n",
    "# Using RFE-selected features for SHAP analysis\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Create and save a SHAP summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance Plot')\n",
    "output_file_shap = \"social_shap_summary_plot_brf.png\"\n",
    "plt.savefig(output_file_shap)\n",
    "print(f\"SHAP plot saved successfully as '{output_file_shap}'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7eb373-ce9a-4c77-b30f-c5a23fabea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "\n",
      "Data has been cleaned and prepared for modeling.\n",
      "Final feature set shape: (99244, 48)\n",
      "\n",
      "Removed multicollinear feature: Household Composition_NOT APPLICABLE\n",
      "New feature set shape after removing multicollinearity: (99244, 47)\n",
      "\n",
      "Performing Recursive Feature Elimination (RFE) to select top 10 features...\n",
      "RFE selected the following features: ['Transgender_UNKNOWN', 'Hispanic Ethnicity_UNKNOWN', 'Race_UNKNOWN RACE', 'Race_WHITE ONLY', 'Living Situation_PRIVATE RESIDENCE', 'Household Composition_UNKNOWN', 'Veteran Status_UNKNOWN', 'Employment Status_UNKNOWN EMPLOYMENT STATUS', 'Education Status_UNKNOWN', 'Special Education Services_UNKNOWN']\n",
      "\n",
      "Original class distribution in training data: Counter({'YES': 66984, 'NO': 1794, 'UNKNOWN': 692})\n",
      "\n",
      "Training the final BalancedRandomForestClassifier on RFE-selected data...\n",
      "Model training complete!\n",
      "\n",
      "Model Accuracy: 0.9646\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.00      0.00      0.00       769\n",
      "     UNKNOWN       0.58      0.14      0.22       296\n",
      "         YES       0.97      1.00      0.98     28709\n",
      "\n",
      "    accuracy                           0.96     29774\n",
      "   macro avg       0.51      0.38      0.40     29774\n",
      "weighted avg       0.94      0.96      0.95     29774\n",
      "\n",
      "\n",
      "Generating SHAP summary plot for model interpretability...\n",
      "SHAP plot saved successfully as 'social_shap_summary_plot_brf.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "# Suppress potential warnings from scikit-learn and imbalanced-learn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Define File Path and Columns ---\n",
    "\n",
    "# The file path to your social data subset.\n",
    "file_path = r\"C:\\Users\\arunc\\OneDrive\\Desktop\\Python Project\\Female data consolidated\\Social_data_part2.csv\"\n",
    "\n",
    "# The columns relevant to this dataset, as requested.\n",
    "# The `Mental Illness` column is our target.\n",
    "columns_to_use = [\n",
    "    'Transgender', 'Sexual Orientation', 'Hispanic Ethnicity', 'Race',\n",
    "    'Living Situation', 'Household Composition', 'Preferred Language',\n",
    "    'Religious Preference', 'Veteran Status', 'Employment Status',\n",
    "    'Number Of Hours Worked Each Week', 'Education Status',\n",
    "    'Special Education Services', 'Mental Illness'\n",
    "]\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# We need to make sure the data contains only the columns we need for this analysis\n",
    "# and handle any missing values in the target variable.\n",
    "data = data[columns_to_use]\n",
    "target_column = 'Mental Illness'\n",
    "data.dropna(subset=[target_column], inplace=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Convert categorical features to dummy/indicator variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"\\nData has been cleaned and prepared for modeling.\")\n",
    "print(f\"Final feature set shape: {X_encoded.shape}\")\n",
    "\n",
    "# --- Drop Multicollinear Features ---\n",
    "if 'Household Composition_NOT APPLICABLE' in X_encoded.columns:\n",
    "    X_encoded = X_encoded.drop(columns=['Household Composition_NOT APPLICABLE'])\n",
    "    print(\"\\nRemoved multicollinear feature: Household Composition_NOT APPLICABLE\")\n",
    "    print(f\"New feature set shape after removing multicollinearity: {X_encoded.shape}\")\n",
    "\n",
    "# --- 3. Feature Selection with RFE ---\n",
    "\n",
    "print(\"\\nPerforming Recursive Feature Elimination (RFE) to select top 10 features...\")\n",
    "# Use BalancedRandomForestClassifier as the estimator for RFE\n",
    "rfe_estimator = BalancedRandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, sampling_strategy='not majority')\n",
    "rfe = RFE(estimator=rfe_estimator, n_features_to_select=10, step=1)\n",
    "rfe.fit(X_encoded, y)\n",
    "\n",
    "# Get the list of top 10 selected features\n",
    "selected_features = X_encoded.columns[rfe.support_].tolist()\n",
    "print(f\"RFE selected the following features: {selected_features}\")\n",
    "\n",
    "# Filter the data to include only the selected features\n",
    "X_rfe = X_encoded[selected_features]\n",
    "\n",
    "# --- 4. Train-Test Split on RFE-selected data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\"\\nOriginal class distribution in training data:\", Counter(y_train))\n",
    "\n",
    "# --- 5. Train the BalancedRandomForestClassifier on RFE-selected data ---\n",
    "model = BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, sampling_strategy='not majority')\n",
    "print(\"\\nTraining the final BalancedRandomForestClassifier on RFE-selected data...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# --- 6. Evaluate the Model ---\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --- 7. Generate SHAP Summary Plot for Interpretability ---\n",
    "print(\"\\nGenerating SHAP summary plot for model interpretability...\")\n",
    "\n",
    "# Using RFE-selected features for SHAP analysis\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Create and save a SHAP summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance Plot')\n",
    "output_file_shap = \"social_shap_summary_plot_brf.png\"\n",
    "plt.savefig(output_file_shap)\n",
    "print(f\"SHAP plot saved successfully as '{output_file_shap}'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db025a-2976-43d3-b624-6fc0eed9f8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
